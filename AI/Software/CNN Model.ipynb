{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff0660e-81e8-4c16-a05e-ba6bc388288d",
   "metadata": {},
   "source": [
    "# Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97e5141d-8823-46ff-a6f2-f401d26a446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, BatchNormalization, GlobalAveragePooling1D, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6312507c-21b0-4c78-8532-63cb6212cef9",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3cfcbb2-f385-4b31-8550-246287d00300",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 20\n",
    "window_size = 3 * sampling_rate  # 60 timesteps\n",
    "wand_classes = [\"Circle\", \"Infinity\", \"None\", \"Square\", \"Triangle\", \"Wave\", \"Zigzag\"]\n",
    "num_channels_online = 45\n",
    "num_channels_wand = 6\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda73396-e40f-4c5f-a316-a6723aac2519",
   "metadata": {},
   "source": [
    "# Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f856f166-e22a-4691-b988-265642cbd4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def lowpass_filter(data, cutoff=5, fs=50, order=4):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "def normalize_window(window):\n",
    "    return (window - np.mean(window, axis=0)) / (np.std(window, axis=0) + 1e-8)\n",
    "\n",
    "def pad_or_crop(sample, window_size):\n",
    "    n_rows, n_cols = sample.shape\n",
    "    if n_rows > window_size:\n",
    "        return sample[:window_size, :]\n",
    "    elif n_rows < window_size:\n",
    "        pad_width = ((0, window_size - n_rows), (0, 0))\n",
    "        return np.pad(sample, pad_width, mode='constant')\n",
    "    else:\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2cbc7-8b96-4c6e-9f71-710796bfdc08",
   "metadata": {},
   "source": [
    "# Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68f7f103-f7bb-435e-9775-806d28a8b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_dataset(dataset_path, window_size=60, \n",
    "                                   selected_channels=None, class_list=None, use_labels_folder=True):\n",
    "    \"\"\"Load dataset and apply global normalization.\"\"\"\n",
    "    data_folder = os.path.join(dataset_path, \"data_clean\")\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    data_files = sorted(os.listdir(data_folder))\n",
    "\n",
    "    if use_labels_folder:\n",
    "        label_folder = os.path.join(dataset_path, \"label\")\n",
    "        label_files = sorted(os.listdir(label_folder))\n",
    "        for data_file, label_file in zip(data_files, label_files):\n",
    "            arr = pd.read_csv(os.path.join(data_folder, data_file)).values\n",
    "            if selected_channels:\n",
    "                arr = arr[:, selected_channels]\n",
    "            arr = pad_or_crop(arr, window_size)\n",
    "            X_list.append(arr)\n",
    "\n",
    "            with open(os.path.join(label_folder, label_file), 'r') as f:\n",
    "                y_list.append(f.read().strip())\n",
    "    else:\n",
    "        for data_file in data_files:\n",
    "            arr = pd.read_csv(os.path.join(data_folder, data_file)).values\n",
    "            if selected_channels:\n",
    "                arr = arr[:, selected_channels]\n",
    "            arr = pad_or_crop(arr, window_size)\n",
    "            X_list.append(arr)\n",
    "\n",
    "            # Infer label from filename\n",
    "            label = os.path.splitext(data_file)[0].split(\"_\")[0].capitalize()\n",
    "            y_list.append(label)\n",
    "\n",
    "    X_stack = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    # Compute global mean/std over all windows\n",
    "    all_data = X_stack.reshape(-1, X_stack.shape[2])\n",
    "    channel_mean = all_data.mean(axis=0)\n",
    "    channel_std = all_data.std(axis=0)\n",
    "    channel_std[channel_std < 1e-6] = 1.0\n",
    "\n",
    "    # Apply global normalization\n",
    "    X_norm = (X_stack - channel_mean) / channel_std\n",
    "\n",
    "    # Encode labels\n",
    "    encoder = LabelEncoder()\n",
    "    if class_list:\n",
    "        encoder.fit(class_list)\n",
    "    else:\n",
    "        encoder.fit(y)\n",
    "    y_encoded = encoder.transform(y)\n",
    "    y_onehot = np.eye(len(encoder.classes_))[y_encoded]\n",
    "\n",
    "    print(f\"Loaded {len(X_norm)} samples, {X_norm.shape[1]} timesteps, {X_norm.shape[2]} channels\")\n",
    "    print(f\"Classes: {list(encoder.classes_)}\")\n",
    "\n",
    "    return X_norm, y_onehot, encoder, channel_mean, channel_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dce05e-d3f3-4b27-9d00-f2ac7ba4a991",
   "metadata": {},
   "source": [
    "# Train base model on online dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb1560c7-5085-47f0-a372-31a26a79d9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 810 samples, 60 timesteps, 45 channels\n",
      "Classes: ['label\\n0', 'label\\n1', 'label\\n10', 'label\\n2', 'label\\n3', 'label\\n4', 'label\\n5', 'label\\n6']\n"
     ]
    }
   ],
   "source": [
    "dataset_online_path = r\"C:\\Users\\CK Cheong\\Desktop\\rosbag\\data\"\n",
    "X_online, y_online, encoder_online, mean_online, std_online = load_preprocess_dataset(\n",
    "    dataset_online_path,\n",
    "    window_size=window_size,\n",
    "    selected_channels=None,\n",
    "    class_list=None,\n",
    "    use_labels_folder=True\n",
    ")\n",
    "\n",
    "# Split for training/validation\n",
    "X_train_online, X_val_online, y_train_online, y_val_online = train_test_split(\n",
    "    X_online, y_online, test_size=0.2, stratify=y_online, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ae1b1-d8b7-4ece-8e4a-658dd92cf7c9",
   "metadata": {},
   "source": [
    "# Base CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c98bba8-1018-4e6a-9de4-ef996e4ea86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m7,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m10,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,912</span> (202.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,912\u001b[0m (202.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,464</span> (201.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m51,464\u001b[0m (201.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.2392 - loss: 2.0538 - val_accuracy: 0.3395 - val_loss: 1.8168\n",
      "Epoch 2/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4074 - loss: 1.5789 - val_accuracy: 0.4877 - val_loss: 1.5700\n",
      "Epoch 3/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5139 - loss: 1.2878 - val_accuracy: 0.5926 - val_loss: 1.3450\n",
      "Epoch 4/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5988 - loss: 1.0829 - val_accuracy: 0.6790 - val_loss: 1.0868\n",
      "Epoch 5/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6620 - loss: 0.9063 - val_accuracy: 0.7160 - val_loss: 0.9003\n",
      "Epoch 6/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7052 - loss: 0.8509 - val_accuracy: 0.7654 - val_loss: 0.7521\n",
      "Epoch 7/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7515 - loss: 0.7140 - val_accuracy: 0.7469 - val_loss: 0.7023\n",
      "Epoch 8/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7840 - loss: 0.6464 - val_accuracy: 0.7778 - val_loss: 0.6271\n",
      "Epoch 9/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7731 - loss: 0.6305 - val_accuracy: 0.7778 - val_loss: 0.5935\n",
      "Epoch 10/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7994 - loss: 0.5838 - val_accuracy: 0.8210 - val_loss: 0.5413\n",
      "Epoch 11/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8272 - loss: 0.5059 - val_accuracy: 0.8272 - val_loss: 0.5426\n",
      "Epoch 12/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8457 - loss: 0.4770 - val_accuracy: 0.8086 - val_loss: 0.5258\n",
      "Epoch 13/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8302 - loss: 0.5041 - val_accuracy: 0.8333 - val_loss: 0.5289\n",
      "Epoch 14/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8549 - loss: 0.4445 - val_accuracy: 0.8272 - val_loss: 0.5081\n",
      "Epoch 15/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8611 - loss: 0.4387 - val_accuracy: 0.8457 - val_loss: 0.4881\n",
      "Epoch 16/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8843 - loss: 0.3771 - val_accuracy: 0.8457 - val_loss: 0.5007\n",
      "Epoch 17/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8735 - loss: 0.3920 - val_accuracy: 0.8457 - val_loss: 0.4784\n",
      "Epoch 18/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8704 - loss: 0.3796 - val_accuracy: 0.7963 - val_loss: 0.4963\n",
      "Epoch 19/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8673 - loss: 0.3801 - val_accuracy: 0.8457 - val_loss: 0.4692\n",
      "Epoch 20/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8719 - loss: 0.3802 - val_accuracy: 0.8272 - val_loss: 0.4840\n",
      "Epoch 21/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9074 - loss: 0.3172 - val_accuracy: 0.8272 - val_loss: 0.4652\n",
      "Epoch 22/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9012 - loss: 0.3233 - val_accuracy: 0.8272 - val_loss: 0.5370\n",
      "Epoch 23/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8920 - loss: 0.3268 - val_accuracy: 0.8519 - val_loss: 0.4908\n",
      "Epoch 24/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9198 - loss: 0.3397 - val_accuracy: 0.8333 - val_loss: 0.5100\n",
      "Epoch 25/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8873 - loss: 0.3647 - val_accuracy: 0.8642 - val_loss: 0.4753\n",
      "Epoch 26/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9090 - loss: 0.3030 - val_accuracy: 0.8395 - val_loss: 0.4699\n",
      "Epoch 27/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9043 - loss: 0.2993 - val_accuracy: 0.8272 - val_loss: 0.4848\n",
      "Epoch 28/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8997 - loss: 0.2819 - val_accuracy: 0.8272 - val_loss: 0.6194\n",
      "Epoch 29/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9167 - loss: 0.3071 - val_accuracy: 0.8025 - val_loss: 0.5607\n",
      "Epoch 30/30\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9151 - loss: 0.2974 - val_accuracy: 0.8148 - val_loss: 0.5320\n"
     ]
    }
   ],
   "source": [
    "base_model = Sequential([\n",
    "    tf.keras.Input(shape=(window_size, num_channels_online)),\n",
    "    \n",
    "    Conv1D(32, 5, kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),  \n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(64, 5, kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),  \n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv1D(128, 3, kernel_regularizer=l2(weight_decay)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),  \n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(weight_decay)),\n",
    "    Dropout(0.4),\n",
    "    Dense(len(encoder_online.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "base_model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "base_model.summary()\n",
    "\n",
    "history_online = base_model.fit(\n",
    "    X_train_online, y_train_online,\n",
    "    validation_data=(X_val_online, y_val_online),\n",
    "    epochs=30,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Save base model\n",
    "base_model.save(\"base_model_online.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82e5e3-3d11-4ecc-89c9-f26ad35db1d2",
   "metadata": {},
   "source": [
    "# Clean wand dataset and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "737426ab-d668-4732-b126-ce2386f94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4738 samples, 60 timesteps, 6 channels\n",
      "Classes: ['Circle', 'Infinity', 'None', 'Square', 'Triangle', 'Wave', 'Zigzag']\n"
     ]
    }
   ],
   "source": [
    "wand_dataset = r\"C:\\Users\\CK Cheong\\Documents\\GitHub\\CG4002-Wizard-Game-Project\\AI\\wand_dataset\"\n",
    "\n",
    "X_wand, y_wand, encoder_wand, mean_wand, std_wand = load_preprocess_dataset(\n",
    "    wand_dataset,\n",
    "    window_size=window_size,\n",
    "    selected_channels=[0,1,2,3,4,5],\n",
    "    class_list=wand_classes,\n",
    "    use_labels_folder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e38310-adc6-4de5-853c-d31288e8774d",
   "metadata": {},
   "source": [
    "# Compute mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa7b7ec0-6a02-4f86-9190-cb3188e756d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_std.h generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Split train/val \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_wand, y_wand, test_size=0.2, stratify=y_wand, random_state=42\n",
    ")\n",
    "\n",
    "# Save the mean and std values to .npy (from loader)\n",
    "np.save(\"mean_std.npy\", {\"mean\": mean_wand, \"std\": std_wand})\n",
    "\n",
    "data = np.load(\"mean_std.npy\", allow_pickle=True).item()\n",
    "mean = data[\"mean\"]\n",
    "std  = data[\"std\"]\n",
    "\n",
    "with open(\"mean_std.h\", \"w\") as f:\n",
    "    f.write(\"#ifndef MEAN_STD_H\\n#define MEAN_STD_H\\n\\n\")\n",
    "    f.write(\"#include <cstdint>\\n\\n\")\n",
    "\n",
    "    f.write(f\"const float channel_mean[{len(mean)}] = {{\")\n",
    "    f.write(\", \".join(f\"{m:.8f}\" for m in mean))\n",
    "    f.write(\"};\\n\")\n",
    "\n",
    "    f.write(f\"const float channel_std[{len(std)}] = {{\")\n",
    "    f.write(\", \".join(f\"{s:.8f}\" for s in std))\n",
    "    f.write(\"};\\n\\n\")\n",
    "\n",
    "    f.write(\"#endif // MEAN_STD_H\\n\")\n",
    "\n",
    "print(\"mean_std.h generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b07c904-1847-4e66-99b6-8ee540faf6fc",
   "metadata": {},
   "source": [
    "# Apply augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95345f32-297a-4943-9c6a-f2974d25a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 1.015813454837845, 1: 1.0679064525218371, 2: 1.0177228786251342, 3: 0.9898145729955602, 4: 0.9898145729955602, 5: 0.9668367346938775, 6: 0.9599797365754813}\n"
     ]
    }
   ],
   "source": [
    "def augment_window_tf(window, label):\n",
    "    # Ensure window is float32\n",
    "    window = tf.cast(window, tf.float32)  \n",
    "    # Gaussian noise\n",
    "    noise = tf.random.normal(shape=tf.shape(window), mean=0.0, stddev=0.01, dtype=tf.float32)\n",
    "    # Random scale factor\n",
    "    scale = tf.random.uniform([], 0.9, 1.1, dtype=tf.float32)\n",
    "    # Random time shift\n",
    "    shift = tf.random.uniform([], -3, 3, dtype=tf.int32)\n",
    "    # Apply augmentations\n",
    "    window = window + noise\n",
    "    window = window * scale\n",
    "    window = tf.roll(window, shift=shift, axis=0)\n",
    "    \n",
    "    return window, label\n",
    "\n",
    "def make_dataset(X, y, batch_size=32, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(X), reshuffle_each_iteration=True)\n",
    "        ds = ds.map(augment_window_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(X_train, y_train, batch_size=16, training=True)\n",
    "val_ds   = make_dataset(X_val, y_val, batch_size=16, training=False)\n",
    "\n",
    "# Compute Class Weights (for balancing) \n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_labels),\n",
    "    y=y_train_labels\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Use a fresh checkpoint filename to avoid conflicts with old models\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"cnn_wand_best_fresh.keras\", monitor='val_accuracy',\n",
    "    save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "# Add learning rate reduction for better convergence\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5b063-7bd6-40bc-a8a8-2b6ae6fd98a1",
   "metadata": {},
   "source": [
    "# Simplified CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "961a795d-2dc7-47ee-8406-7e98479d25dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2518 - loss: 1.8594\n",
      "Epoch 1: val_accuracy improved from None to 0.57278, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3702 - loss: 1.7067 - val_accuracy: 0.5728 - val_loss: 1.4833 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5760 - loss: 1.3492\n",
      "Epoch 2: val_accuracy improved from 0.57278 to 0.66456, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5997 - loss: 1.2859 - val_accuracy: 0.6646 - val_loss: 1.1291 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6572 - loss: 1.1192\n",
      "Epoch 3: val_accuracy improved from 0.66456 to 0.72574, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6805 - loss: 1.0522 - val_accuracy: 0.7257 - val_loss: 0.9463 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7232 - loss: 0.9176\n",
      "Epoch 4: val_accuracy improved from 0.72574 to 0.78270, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7314 - loss: 0.8932 - val_accuracy: 0.7827 - val_loss: 0.7891 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.7875\n",
      "Epoch 5: val_accuracy did not improve from 0.78270\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7652 - loss: 0.7743 - val_accuracy: 0.7700 - val_loss: 0.7809 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7855 - loss: 0.7005\n",
      "Epoch 6: val_accuracy improved from 0.78270 to 0.83017, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7945 - loss: 0.6832 - val_accuracy: 0.8302 - val_loss: 0.6581 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8098 - loss: 0.6308\n",
      "Epoch 7: val_accuracy improved from 0.83017 to 0.83650, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8182 - loss: 0.6156 - val_accuracy: 0.8365 - val_loss: 0.5833 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8402 - loss: 0.5530\n",
      "Epoch 8: val_accuracy improved from 0.83650 to 0.87658, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8409 - loss: 0.5618 - val_accuracy: 0.8766 - val_loss: 0.5128 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8466 - loss: 0.5308\n",
      "Epoch 9: val_accuracy improved from 0.87658 to 0.89241, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8525 - loss: 0.5126 - val_accuracy: 0.8924 - val_loss: 0.4879 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8570 - loss: 0.4925\n",
      "Epoch 10: val_accuracy did not improve from 0.89241\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8583 - loss: 0.4829 - val_accuracy: 0.8840 - val_loss: 0.4615 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8597 - loss: 0.4789\n",
      "Epoch 11: val_accuracy improved from 0.89241 to 0.89768, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8712 - loss: 0.4547 - val_accuracy: 0.8977 - val_loss: 0.4253 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8941 - loss: 0.4167\n",
      "Epoch 12: val_accuracy did not improve from 0.89768\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8836 - loss: 0.4252 - val_accuracy: 0.8660 - val_loss: 0.4627 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8922 - loss: 0.3753\n",
      "Epoch 13: val_accuracy did not improve from 0.89768\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8799 - loss: 0.4076 - val_accuracy: 0.8745 - val_loss: 0.4281 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8880 - loss: 0.3808\n",
      "Epoch 14: val_accuracy improved from 0.89768 to 0.91667, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8884 - loss: 0.3731 - val_accuracy: 0.9167 - val_loss: 0.3749 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8843 - loss: 0.3797\n",
      "Epoch 15: val_accuracy improved from 0.91667 to 0.91878, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8892 - loss: 0.3728 - val_accuracy: 0.9188 - val_loss: 0.3486 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.3617\n",
      "Epoch 16: val_accuracy did not improve from 0.91878\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8984 - loss: 0.3518 - val_accuracy: 0.8966 - val_loss: 0.3911 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.3363\n",
      "Epoch 17: val_accuracy improved from 0.91878 to 0.92194, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8997 - loss: 0.3383 - val_accuracy: 0.9219 - val_loss: 0.3489 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9056 - loss: 0.3361\n",
      "Epoch 18: val_accuracy did not improve from 0.92194\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9092 - loss: 0.3188 - val_accuracy: 0.9177 - val_loss: 0.3364 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9173 - loss: 0.2858\n",
      "Epoch 19: val_accuracy improved from 0.92194 to 0.93354, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9113 - loss: 0.2925 - val_accuracy: 0.9335 - val_loss: 0.3093 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9149 - loss: 0.2852\n",
      "Epoch 20: val_accuracy did not improve from 0.93354\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9108 - loss: 0.2950 - val_accuracy: 0.9230 - val_loss: 0.3191 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9004 - loss: 0.3280\n",
      "Epoch 21: val_accuracy improved from 0.93354 to 0.93565, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9058 - loss: 0.2999 - val_accuracy: 0.9357 - val_loss: 0.2894 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9070 - loss: 0.2988\n",
      "Epoch 22: val_accuracy did not improve from 0.93565\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9111 - loss: 0.2866 - val_accuracy: 0.9293 - val_loss: 0.3156 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9093 - loss: 0.2832\n",
      "Epoch 23: val_accuracy did not improve from 0.93565\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9127 - loss: 0.2758 - val_accuracy: 0.9146 - val_loss: 0.3394 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9163 - loss: 0.2646\n",
      "Epoch 24: val_accuracy did not improve from 0.93565\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9164 - loss: 0.2641 - val_accuracy: 0.9346 - val_loss: 0.2803 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9322 - loss: 0.2247\n",
      "Epoch 25: val_accuracy improved from 0.93565 to 0.93987, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9235 - loss: 0.2471 - val_accuracy: 0.9399 - val_loss: 0.2665 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9270 - loss: 0.2426\n",
      "Epoch 26: val_accuracy improved from 0.93987 to 0.94726, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9282 - loss: 0.2367 - val_accuracy: 0.9473 - val_loss: 0.2656 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9307 - loss: 0.2336\n",
      "Epoch 27: val_accuracy did not improve from 0.94726\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9317 - loss: 0.2305 - val_accuracy: 0.9451 - val_loss: 0.2661 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9342 - loss: 0.2300\n",
      "Epoch 28: val_accuracy improved from 0.94726 to 0.94937, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9309 - loss: 0.2315 - val_accuracy: 0.9494 - val_loss: 0.2529 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9229 - loss: 0.2414\n",
      "Epoch 29: val_accuracy improved from 0.94937 to 0.95148, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9301 - loss: 0.2258 - val_accuracy: 0.9515 - val_loss: 0.2384 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9280 - loss: 0.2263\n",
      "Epoch 30: val_accuracy did not improve from 0.95148\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9303 - loss: 0.2275 - val_accuracy: 0.9146 - val_loss: 0.3244 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.1896\n",
      "Epoch 31: val_accuracy did not improve from 0.95148\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.2097 - val_accuracy: 0.9494 - val_loss: 0.2346 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.1847\n",
      "Epoch 32: val_accuracy did not improve from 0.95148\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9398 - loss: 0.1937 - val_accuracy: 0.9515 - val_loss: 0.2588 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9347 - loss: 0.2250\n",
      "Epoch 33: val_accuracy did not improve from 0.95148\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9288 - loss: 0.2201 - val_accuracy: 0.9515 - val_loss: 0.2412 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9348 - loss: 0.2056\n",
      "Epoch 34: val_accuracy did not improve from 0.95148\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9356 - loss: 0.2106 - val_accuracy: 0.9483 - val_loss: 0.2458 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9372 - loss: 0.2164\n",
      "Epoch 35: val_accuracy improved from 0.95148 to 0.95359, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9348 - loss: 0.2113 - val_accuracy: 0.9536 - val_loss: 0.2488 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9443 - loss: 0.1870\n",
      "Epoch 36: val_accuracy did not improve from 0.95359\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9404 - loss: 0.1889 - val_accuracy: 0.9262 - val_loss: 0.2933 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9367 - loss: 0.1892\n",
      "Epoch 37: val_accuracy did not improve from 0.95359\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.1852 - val_accuracy: 0.9515 - val_loss: 0.2513 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.1472\n",
      "Epoch 38: val_accuracy improved from 0.95359 to 0.96097, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9520 - loss: 0.1637 - val_accuracy: 0.9610 - val_loss: 0.2271 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9518 - loss: 0.1582\n",
      "Epoch 39: val_accuracy improved from 0.96097 to 0.96308, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9496 - loss: 0.1620 - val_accuracy: 0.9631 - val_loss: 0.2326 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9549 - loss: 0.1513\n",
      "Epoch 40: val_accuracy did not improve from 0.96308\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9512 - loss: 0.1614 - val_accuracy: 0.9473 - val_loss: 0.2485 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9484 - loss: 0.1628\n",
      "Epoch 41: val_accuracy did not improve from 0.96308\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9462 - loss: 0.1635 - val_accuracy: 0.9620 - val_loss: 0.2315 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9572 - loss: 0.1497\n",
      "Epoch 42: val_accuracy improved from 0.96308 to 0.96624, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.1627 - val_accuracy: 0.9662 - val_loss: 0.2310 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1688\n",
      "Epoch 43: val_accuracy did not improve from 0.96624\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9515 - loss: 0.1614 - val_accuracy: 0.9494 - val_loss: 0.2452 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9521 - loss: 0.1586\n",
      "Epoch 44: val_accuracy did not improve from 0.96624\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9551 - loss: 0.1508 - val_accuracy: 0.9652 - val_loss: 0.2254 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9534 - loss: 0.1488\n",
      "Epoch 45: val_accuracy did not improve from 0.96624\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9567 - loss: 0.1454 - val_accuracy: 0.9578 - val_loss: 0.2219 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9505 - loss: 0.1557\n",
      "Epoch 46: val_accuracy did not improve from 0.96624\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9562 - loss: 0.1509 - val_accuracy: 0.9589 - val_loss: 0.2246 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1375\n",
      "Epoch 47: val_accuracy did not improve from 0.96624\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9517 - loss: 0.1455 - val_accuracy: 0.9662 - val_loss: 0.2158 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9614 - loss: 0.1386\n",
      "Epoch 48: val_accuracy did not improve from 0.96624\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9570 - loss: 0.1415 - val_accuracy: 0.9652 - val_loss: 0.2160 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9534 - loss: 0.1503\n",
      "Epoch 49: val_accuracy improved from 0.96624 to 0.96835, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9541 - loss: 0.1399 - val_accuracy: 0.9684 - val_loss: 0.2167 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m229/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.1419\n",
      "Epoch 50: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9541 - loss: 0.1449 - val_accuracy: 0.9662 - val_loss: 0.2124 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9640 - loss: 0.1251\n",
      "Epoch 51: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9544 - loss: 0.1455 - val_accuracy: 0.9610 - val_loss: 0.2220 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9575 - loss: 0.1396\n",
      "Epoch 52: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9546 - loss: 0.1486 - val_accuracy: 0.9631 - val_loss: 0.2118 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9495 - loss: 0.1522\n",
      "Epoch 53: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9520 - loss: 0.1499 - val_accuracy: 0.9641 - val_loss: 0.2158 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1422\n",
      "Epoch 54: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9570 - loss: 0.1462 - val_accuracy: 0.9673 - val_loss: 0.2149 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.1324\n",
      "Epoch 55: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9573 - loss: 0.1425 - val_accuracy: 0.9610 - val_loss: 0.2253 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9494 - loss: 0.1492\n",
      "Epoch 56: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9520 - loss: 0.1488 - val_accuracy: 0.9631 - val_loss: 0.2142 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1454\n",
      "Epoch 57: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.1454 - val_accuracy: 0.9684 - val_loss: 0.2114 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9595 - loss: 0.1374\n",
      "Epoch 58: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.1359 - val_accuracy: 0.9641 - val_loss: 0.2202 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9660 - loss: 0.1263\n",
      "Epoch 59: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9583 - loss: 0.1375 - val_accuracy: 0.9620 - val_loss: 0.2107 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9622 - loss: 0.1374\n",
      "Epoch 60: val_accuracy did not improve from 0.96835\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1324 - val_accuracy: 0.9684 - val_loss: 0.2211 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9622 - loss: 0.1360\n",
      "Epoch 61: val_accuracy improved from 0.96835 to 0.96941, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9609 - loss: 0.1350 - val_accuracy: 0.9694 - val_loss: 0.2102 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9619 - loss: 0.1264\n",
      "Epoch 62: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1252 - val_accuracy: 0.9652 - val_loss: 0.2145 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9595 - loss: 0.1436\n",
      "Epoch 63: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9575 - loss: 0.1431 - val_accuracy: 0.9568 - val_loss: 0.2423 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9612 - loss: 0.1273\n",
      "Epoch 64: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9544 - loss: 0.1416 - val_accuracy: 0.9652 - val_loss: 0.2213 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9605 - loss: 0.1463\n",
      "Epoch 65: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1413 - val_accuracy: 0.9620 - val_loss: 0.2231 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.1210\n",
      "Epoch 66: val_accuracy did not improve from 0.96941\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1226 - val_accuracy: 0.9684 - val_loss: 0.2196 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9604 - loss: 0.1268\n",
      "Epoch 67: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9546 - loss: 0.1457 - val_accuracy: 0.9673 - val_loss: 0.2111 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.1083\n",
      "Epoch 68: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1190 - val_accuracy: 0.9684 - val_loss: 0.2095 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9640 - loss: 0.1179\n",
      "Epoch 69: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9615 - loss: 0.1249 - val_accuracy: 0.9673 - val_loss: 0.2093 - learning_rate: 1.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9677 - loss: 0.1179\n",
      "Epoch 70: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9615 - loss: 0.1233 - val_accuracy: 0.9631 - val_loss: 0.2103 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9661 - loss: 0.1267\n",
      "Epoch 71: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9675 - loss: 0.1188 - val_accuracy: 0.9652 - val_loss: 0.2100 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m230/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9580 - loss: 0.1325\n",
      "Epoch 72: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9607 - loss: 0.1295 - val_accuracy: 0.9673 - val_loss: 0.2155 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9616 - loss: 0.1292\n",
      "Epoch 73: val_accuracy did not improve from 0.96941\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.1342 - val_accuracy: 0.9684 - val_loss: 0.2098 - learning_rate: 1.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9534 - loss: 0.1380\n",
      "Epoch 74: val_accuracy improved from 0.96941 to 0.97152, saving model to cnn_wand_best_fresh.keras\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9588 - loss: 0.1295 - val_accuracy: 0.9715 - val_loss: 0.2101 - learning_rate: 1.2500e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m230/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.1165\n",
      "Epoch 75: val_accuracy did not improve from 0.97152\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9678 - loss: 0.1181 - val_accuracy: 0.9694 - val_loss: 0.2105 - learning_rate: 6.2500e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.1253\n",
      "Epoch 76: val_accuracy did not improve from 0.97152\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9633 - loss: 0.1204 - val_accuracy: 0.9705 - val_loss: 0.2101 - learning_rate: 6.2500e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.1237\n",
      "Epoch 77: val_accuracy did not improve from 0.97152\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.1207 - val_accuracy: 0.9673 - val_loss: 0.2112 - learning_rate: 6.2500e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9637 - loss: 0.1184\n",
      "Epoch 78: val_accuracy did not improve from 0.97152\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.1227 - val_accuracy: 0.9673 - val_loss: 0.2055 - learning_rate: 6.2500e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.1229\n",
      "Epoch 79: val_accuracy did not improve from 0.97152\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9599 - loss: 0.1271 - val_accuracy: 0.9673 - val_loss: 0.2084 - learning_rate: 6.2500e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9650 - loss: 0.1213\n",
      "Epoch 80: val_accuracy did not improve from 0.97152\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.1241 - val_accuracy: 0.9662 - val_loss: 0.2074 - learning_rate: 6.2500e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9623 - loss: 0.1250\n",
      "Epoch 81: val_accuracy did not improve from 0.97152\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.1321 - val_accuracy: 0.9684 - val_loss: 0.2084 - learning_rate: 6.2500e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9633 - loss: 0.1206\n",
      "Epoch 82: val_accuracy improved from 0.97152 to 0.97257, saving model to cnn_wand_best_fresh.keras\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9673 - loss: 0.1144 - val_accuracy: 0.9726 - val_loss: 0.2099 - learning_rate: 6.2500e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9663 - loss: 0.1160\n",
      "Epoch 83: val_accuracy did not improve from 0.97257\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9660 - loss: 0.1132 - val_accuracy: 0.9662 - val_loss: 0.2115 - learning_rate: 6.2500e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9603 - loss: 0.1196\n",
      "Epoch 84: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1222 - val_accuracy: 0.9662 - val_loss: 0.2082 - learning_rate: 3.1250e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9624 - loss: 0.1233\n",
      "Epoch 85: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9649 - loss: 0.1219 - val_accuracy: 0.9684 - val_loss: 0.2113 - learning_rate: 3.1250e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9700 - loss: 0.1173\n",
      "Epoch 86: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9694 - loss: 0.1161 - val_accuracy: 0.9684 - val_loss: 0.2071 - learning_rate: 3.1250e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9608 - loss: 0.1246\n",
      "Epoch 87: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.1181 - val_accuracy: 0.9694 - val_loss: 0.2060 - learning_rate: 3.1250e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9616 - loss: 0.1393\n",
      "Epoch 88: val_accuracy did not improve from 0.97257\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9644 - loss: 0.1274 - val_accuracy: 0.9694 - val_loss: 0.2092 - learning_rate: 3.1250e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.1040\n",
      "Epoch 89: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.1194 - val_accuracy: 0.9694 - val_loss: 0.2070 - learning_rate: 1.5625e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m236/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.1094\n",
      "Epoch 90: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9678 - loss: 0.1109 - val_accuracy: 0.9715 - val_loss: 0.2092 - learning_rate: 1.5625e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9649 - loss: 0.1151\n",
      "Epoch 91: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.1175 - val_accuracy: 0.9715 - val_loss: 0.2073 - learning_rate: 1.5625e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m234/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9692 - loss: 0.1052\n",
      "Epoch 92: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9670 - loss: 0.1123 - val_accuracy: 0.9705 - val_loss: 0.2099 - learning_rate: 1.5625e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m231/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9669 - loss: 0.1116\n",
      "Epoch 93: val_accuracy did not improve from 0.97257\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1136 - val_accuracy: 0.9715 - val_loss: 0.2097 - learning_rate: 1.5625e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9674 - loss: 0.1112\n",
      "Epoch 94: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9694 - loss: 0.1128 - val_accuracy: 0.9705 - val_loss: 0.2093 - learning_rate: 7.8125e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.1163\n",
      "Epoch 95: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9654 - loss: 0.1181 - val_accuracy: 0.9694 - val_loss: 0.2085 - learning_rate: 7.8125e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m233/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.1206\n",
      "Epoch 96: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.1194 - val_accuracy: 0.9694 - val_loss: 0.2076 - learning_rate: 7.8125e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m235/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9649 - loss: 0.1274\n",
      "Epoch 97: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9657 - loss: 0.1216 - val_accuracy: 0.9694 - val_loss: 0.2089 - learning_rate: 7.8125e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9674 - loss: 0.1117\n",
      "Epoch 98: val_accuracy did not improve from 0.97257\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.1191 - val_accuracy: 0.9694 - val_loss: 0.2092 - learning_rate: 7.8125e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m230/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.1233\n",
      "Epoch 99: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.1112 - val_accuracy: 0.9684 - val_loss: 0.2087 - learning_rate: 3.9063e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m232/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.1190\n",
      "Epoch 100: val_accuracy did not improve from 0.97257\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9691 - loss: 0.1120 - val_accuracy: 0.9694 - val_loss: 0.2086 - learning_rate: 3.9063e-06\n",
      "\n",
      "============================================================\n",
      "TRAINING SUMMARY:\n",
      "============================================================\n",
      "Best validation accuracy: 0.9726 (97.26%)\n",
      "Final validation accuracy: 0.9694 (96.94%)\n",
      "Total epochs trained: 100\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define number of classes\n",
    "num_classes = len(wand_classes)\n",
    "\n",
    "# Model with BatchNorm for training (will be folded after training)\n",
    "simplified_model = Sequential([\n",
    "    tf.keras.Input(shape=(window_size, num_channels_wand)),\n",
    "\n",
    "    Conv1D(16, 3, use_bias=False),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    Conv1D(24, 3, use_bias=False),   \n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(24, activation='relu', use_bias=False),\n",
    "    Dense(num_classes, activation='softmax', use_bias=True)\n",
    "])\n",
    "\n",
    "simplified_model.compile(\n",
    "    optimizer=Adam(0.001),  \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train Model \n",
    "# IMPORTANT: Delete old checkpoint files if they exist to avoid conflicts\n",
    "if os.path.exists(\"cnn_simplified_wand_best.keras\"):\n",
    "    os.remove(\"cnn_simplified_wand_best.keras\")\n",
    "    print(\"Deleted old checkpoint file to avoid conflicts\")\n",
    "\n",
    "history_simplified = simplified_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,  \n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, reduce_lr],  # Only checkpoint and learning rate reduction\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save Final Model (with BatchNorm)\n",
    "simplified_model.save(\"cnn_simplified_wand_augmented.keras\")\n",
    "\n",
    "# Print training summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best validation accuracy: {max(history_simplified.history['val_accuracy']):.4f} ({max(history_simplified.history['val_accuracy'])*100:.2f}%)\")\n",
    "print(f\"Final validation accuracy: {history_simplified.history['val_accuracy'][-1]:.4f} ({history_simplified.history['val_accuracy'][-1]*100:.2f}%)\")\n",
    "print(f\"Total epochs trained: {len(history_simplified.history['val_accuracy'])}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b48e21-d302-4903-89d3-964174fe03c9",
   "metadata": {},
   "source": [
    "# BatchNorm Folding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6df9a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_batchnorm_sequential(model: Sequential, input_shape):\n",
    "    \"\"\"\n",
    "    Fold BatchNorm layers into the preceding Conv1D or Dense layers in a Sequential model.\n",
    "    Works for any Sequential model. Returns a new Sequential model.\n",
    "    input_shape: tuple of (timesteps, channels)\n",
    "    \"\"\"\n",
    "    new_layers = []\n",
    "    skip_next = False\n",
    "\n",
    "    # Create dummy input to build layers dynamically\n",
    "    dummy_input = np.zeros((1,) + input_shape, dtype=np.float32)\n",
    "\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "\n",
    "        # Check if next layer is BatchNorm\n",
    "        if i + 1 < len(model.layers) and isinstance(model.layers[i + 1], BatchNormalization):\n",
    "            bn = model.layers[i + 1]\n",
    "\n",
    "            if isinstance(layer, (Conv1D, Dense)):\n",
    "                # Get original weights\n",
    "                W = layer.get_weights()[0]\n",
    "                b = layer.get_weights()[1] if len(layer.get_weights()) > 1 else np.zeros(W.shape[-1])\n",
    "\n",
    "                # Get BN params\n",
    "                gamma, beta, mean, var = bn.get_weights()\n",
    "                eps = bn.epsilon\n",
    "\n",
    "                # Compute folded weights and bias\n",
    "                scale = gamma / np.sqrt(var + eps)\n",
    "                b_folded = beta + (b - mean) * scale\n",
    "\n",
    "                if isinstance(layer, Conv1D):\n",
    "                    W_folded = W * scale.reshape(1, 1, -1)\n",
    "                else:  # Dense\n",
    "                    W_folded = W * scale.reshape(1, -1)\n",
    "\n",
    "                # Recreate layer with folded weights\n",
    "                config = layer.get_config()\n",
    "                config['use_bias'] = True\n",
    "                new_layer = layer.__class__.from_config(config)\n",
    "\n",
    "                # Build the layer by calling it on dummy input\n",
    "                new_layer(dummy_input)\n",
    "                new_layer.set_weights([W_folded, b_folded])\n",
    "\n",
    "                # Update dummy input for next layer\n",
    "                dummy_input = new_layer(dummy_input)\n",
    "\n",
    "                new_layers.append(new_layer)\n",
    "                skip_next = True  # skip BN layer\n",
    "            else:\n",
    "                # BN after non-foldable layer? keep both\n",
    "                new_layers.append(layer)\n",
    "                dummy_input = layer(dummy_input)\n",
    "        else:\n",
    "            # No BN next, just copy the layer\n",
    "            new_layer = layer.__class__.from_config(layer.get_config())\n",
    "            new_layer(dummy_input)\n",
    "            if layer.get_weights():\n",
    "                new_layer.set_weights(layer.get_weights())\n",
    "            new_layers.append(new_layer)\n",
    "            dummy_input = new_layer(dummy_input)\n",
    "\n",
    "    return Sequential(new_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd6142-33ac-4d6e-b0a0-d8fa7791fa23",
   "metadata": {},
   "source": [
    "# Apply BN folding to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0477ede2-0e37-4f1f-82f6-f3c88b5f26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape: (timesteps, channels)\n",
    "input_shape = (60, 6)\n",
    "\n",
    "# Load original trained model\n",
    "model = load_model(\"cnn_simplified_wand_augmented.keras\")\n",
    "\n",
    "# Fold BN into Conv/Dense layers\n",
    "folded_model = fold_batchnorm_sequential(model, input_shape=(60,6))\n",
    "\n",
    "# Build folded model by calling dummy input\n",
    "dummy_input = np.zeros((1, 60, 6), dtype=np.float32)\n",
    "folded_model(dummy_input)\n",
    "\n",
    "# Save folded model safely\n",
    "folded_model.save(\"folded_cnn_model.keras\")\n",
    "\n",
    "# Original model is untouched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8b456-a271-4273-8053-400f6618f9fc",
   "metadata": {},
   "source": [
    "# Evaluate simplified/folded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4950ea3b-2270-4ebe-a26d-969440477f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Simplified Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Circle       0.98      0.97      0.97       666\n",
      "    Infinity       0.98      0.99      0.99       634\n",
      "        None       0.97      0.97      0.97       665\n",
      "      Square       0.99      0.99      0.99       684\n",
      "    Triangle       0.98      0.98      0.98       684\n",
      "        Wave       0.99      0.98      0.98       700\n",
      "      Zigzag       0.99      0.99      0.99       705\n",
      "\n",
      "    accuracy                           0.98      4738\n",
      "   macro avg       0.98      0.98      0.98      4738\n",
      "weighted avg       0.98      0.98      0.98      4738\n",
      "\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Folded Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Circle       0.98      0.97      0.97       666\n",
      "    Infinity       0.98      0.99      0.99       634\n",
      "        None       0.97      0.97      0.97       665\n",
      "      Square       0.99      0.99      0.99       684\n",
      "    Triangle       0.98      0.98      0.98       684\n",
      "        Wave       0.99      0.98      0.98       700\n",
      "      Zigzag       0.99      0.99      0.99       705\n",
      "\n",
      "    accuracy                           0.98      4738\n",
      "   macro avg       0.98      0.98      0.98      4738\n",
      "weighted avg       0.98      0.98      0.98      4738\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = simplified_model.predict(X_wand)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_wand, axis=1)\n",
    "\n",
    "print(\"Simplified Model\")\n",
    "print(classification_report(\n",
    "    y_true_classes, y_pred_classes,\n",
    "    target_names=wand_classes,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "y_pred = folded_model.predict(X_wand)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_wand, axis=1)\n",
    "\n",
    "print(\"Folded Model\")\n",
    "print(classification_report(\n",
    "    y_true_classes, y_pred_classes,\n",
    "    target_names=wand_classes,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=wand_classes, yticklabels=wand_classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Folded Model)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a333b52-a09d-4bbe-920a-d177a01e0cbb",
   "metadata": {},
   "source": [
    "# Generate test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b474ecb5-f3da-4991-b3e3-7033082ac772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 classes: ['Circle', 'Infinity', 'None', 'Square', 'Triangle', 'Wave', 'Zigzag']\n",
      "Predicted classes: [0 1 2 3 4 4 5 6 6 6]\n",
      "True labels: ['Circle', 'Infinity', 'None', 'Square', 'Triangle', 'Triangle', 'Wave', 'Zigzag', 'Zigzag', 'Zigzag']\n"
     ]
    }
   ],
   "source": [
    "# Load your trained model\n",
    "model = tf.keras.models.load_model(\"folded_cnn_model.keras\")\n",
    "\n",
    "# Parameters\n",
    "num_samples = 10\n",
    "window_size = 60\n",
    "num_channels_wand = 6\n",
    "num_classes = 7\n",
    "clean_dir = r\"C:\\Users\\CK Cheong\\Documents\\GitHub\\CG4002-Wizard-Game-Project\\AI\\wand_dataset\\data_clean\"\n",
    "\n",
    "# Load and preprocess test windows\n",
    "def load_test_windows(num_samples=num_samples):\n",
    "    files = sorted(glob.glob(os.path.join(clean_dir, \"*.csv\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {clean_dir}\")\n",
    "\n",
    "    # Group files by class\n",
    "    class_to_files = {}\n",
    "    for f in files:\n",
    "        label = os.path.basename(f).split(\"_\")[0].capitalize()\n",
    "        class_to_files.setdefault(label, []).append(f)\n",
    "\n",
    "    class_names = list(class_to_files.keys())\n",
    "    num_classes_found = len(class_names)\n",
    "    print(f\"Found {num_classes_found} classes:\", class_names)\n",
    "\n",
    "    if num_classes_found == 0:\n",
    "        raise ValueError(\"No classes found in directory\")\n",
    "\n",
    "    # Ensure at least one per class (if possible)\n",
    "    samples_per_class = {cls: 1 for cls in class_names}\n",
    "    remaining = num_samples - num_classes_found\n",
    "\n",
    "    # Distribute remaining samples proportionally to number of available files\n",
    "    total_files = sum(len(v) for v in class_to_files.values())\n",
    "    for cls in class_names:\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "        cls_fraction = len(class_to_files[cls]) / total_files\n",
    "        add = int(round(cls_fraction * remaining))\n",
    "        samples_per_class[cls] += add\n",
    "\n",
    "    # Adjust if rounding causes overflow/underflow\n",
    "    total_assigned = sum(samples_per_class.values())\n",
    "    while total_assigned > num_samples:\n",
    "        reducible = [c for c, n in samples_per_class.items() if n > 1]\n",
    "        if not reducible:\n",
    "            break\n",
    "        cls = random.choice(reducible)\n",
    "        samples_per_class[cls] -= 1\n",
    "        total_assigned -= 1\n",
    "\n",
    "    while total_assigned < num_samples:\n",
    "        cls = random.choice(class_names)\n",
    "        samples_per_class[cls] += 1\n",
    "        total_assigned += 1\n",
    "\n",
    "    X, labels = [], []\n",
    "\n",
    "    # Sample and preprocess\n",
    "    for cls, n_samples in samples_per_class.items():\n",
    "        class_files = class_to_files[cls]\n",
    "        random.shuffle(class_files)\n",
    "        chosen_files = class_files[:n_samples]\n",
    "\n",
    "        for f in chosen_files:\n",
    "            df = pd.read_csv(f)\n",
    "            arr = df.values.astype(np.float32)\n",
    "\n",
    "            # Adjust number of channels\n",
    "            if arr.shape[1] != num_channels_wand:\n",
    "                if arr.shape[1] > num_channels_wand:\n",
    "                    arr = arr[:, -num_channels_wand:]\n",
    "                else:\n",
    "                    print(\"Skipping (wrong #cols):\", f)\n",
    "                    continue\n",
    "\n",
    "            # Pad or crop to window size\n",
    "            if arr.shape[0] > window_size:\n",
    "                arr = arr[:window_size, :]\n",
    "            elif arr.shape[0] < window_size:\n",
    "                pad = np.zeros((window_size - arr.shape[0], arr.shape[1]), dtype=np.float32)\n",
    "                arr = np.vstack([arr, pad])\n",
    "\n",
    "            arr = (arr - mean_wand) / std_wand\n",
    "\n",
    "            X.append(arr)\n",
    "            labels.append(cls)\n",
    "\n",
    "    X = np.stack(X, axis=0)\n",
    "    return X, labels, class_names\n",
    "\n",
    "x_test, y_labels, class_names = load_test_windows(num_samples)\n",
    "\n",
    "# 2. Predict\n",
    "y_pred = model.predict(x_test, verbose=0)\n",
    "pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(\"Predicted classes:\", pred_classes)\n",
    "print(\"True labels:\", y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a10153-f49d-42aa-9723-0d0d552b4b78",
   "metadata": {},
   "source": [
    "# Extract Test Data and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d00544e4-ada5-4e3a-ace9-0d6cf698fc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data and weights exported as float32.\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_data.h\", \"w\") as f:\n",
    "    f.write(\"/* Test dataset from Keras CNN (float32) */\\n\")\n",
    "    f.write(\"#ifndef TEST_DATA_H\\n#define TEST_DATA_H\\n\\n\")\n",
    "    f.write(\"#include <cstdint>\\n\\n\")\n",
    "    f.write(f\"#define NUM_SAMPLES {x_test.shape[0]}\\n\")\n",
    "    f.write(f\"#define INPUT_LEN {window_size}\\n\")\n",
    "    f.write(f\"#define INPUT_CH {num_channels_wand}\\n\")\n",
    "    f.write(f\"#define NUM_CLASSES {num_classes}\\n\\n\")\n",
    "\n",
    "    # Input array\n",
    "    f.write(f\"const float test_inputs[NUM_SAMPLES][INPUT_LEN][INPUT_CH] = {{\\n\")\n",
    "    for n in range(x_test.shape[0]):\n",
    "        f.write(\"  {\\n\")\n",
    "        for t in range(window_size):\n",
    "            row = \", \".join(map(lambda v: f\"{v:.6f}\", x_test[n, t]))\n",
    "            f.write(f\"    {{{row}}},\\n\")\n",
    "        f.write(\"  },\\n\")\n",
    "    f.write(\"};\\n\\n\")\n",
    "\n",
    "    # Output array\n",
    "    f.write(f\"const float test_outputs[NUM_SAMPLES][NUM_CLASSES] = {{\\n\")\n",
    "    for n in range(y_pred.shape[0]):\n",
    "        row = \", \".join(map(lambda v: f\"{v:.6f}\", y_pred[n]))\n",
    "        f.write(f\"  {{{row}}},\\n\")\n",
    "    f.write(\"};\\n\\n\")\n",
    "\n",
    "    f.write(\"#endif // TEST_DATA_H\\n\")\n",
    "\n",
    "with open(\"cnn_weights.h\", \"w\") as f:\n",
    "    f.write(\"// CNN weights (float32)\\n\\n\")\n",
    "    f.write(\"#include <cstdint>\\n\\n\")\n",
    "\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        if not weights:\n",
    "            continue\n",
    "\n",
    "        f.write(f\"// Layer: {layer.name}\\n\")\n",
    "\n",
    "        for i, w in enumerate(weights):\n",
    "            if len(w.shape) == 3:  # Conv1D: (kernel, in, out)\n",
    "                w = np.transpose(w, (2, 1, 0))  # (out, in, k)\n",
    "            # Dense or Bias remain as-is\n",
    "\n",
    "            flat = w.flatten().astype(np.float32)\n",
    "            name = f\"{layer.name}_param{i}\"\n",
    "            f.write(f\"const float {name}[{len(flat)}] = {{\\n\")\n",
    "            f.write(\", \".join(map(lambda v: f\"{v:.6f}\", flat)))\n",
    "            f.write(\"\\n};\\n\\n\")\n",
    "\n",
    "    f.write(\"// End of cnn_weights.h\\n\")\n",
    "\n",
    "print(\"Test data and weights exported as float32.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
